{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Minerando Dados - A maior comunidade de Data Science do Brasil**\n",
    "www.minerandodados.com.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análise de Sentimentos usando Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criando modelos para análise de sentimentos de tweets\n",
    "* Teste com Modelo usando tag de negações\n",
    "* Teste com Modelo usando Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ler arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Tweets_Mg.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exibe as 50 primeiras lihas de tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Text.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conta a quantidade de linhas de tweets neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dataset.Classificacao.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove linhas duplicadas na base de dados\n",
    "    - Problema na coleta dos dados.\n",
    "* Remove Stopwords\n",
    "* Faz Stemming nos dados\n",
    "* Remove caracteres indesejados como links, pontuação etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Separando tweets e suas Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataset['Text']\n",
    "classes = dataset['Classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Instala bibliotecas e baixa a base de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funções de Pre-processamento de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Entenda como funciona cada função**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveStopWords('Eu não gosto do partido, e também não votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemming('Eu não gosto do partido, e também não votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Limpeza_dados('Assita aqui o video do Governador falando sobre a CEMIG https://www.uol.com.br :) ;)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Aplica as 3 funções de Pre-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Aplica a função em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing('Eu não gosto do partido, e também não votaria novamente nesse governante. Assita o video aqui https:// :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize os dados e veja como ficou após o pré-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instancia o objeto que faz a vetorização dos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplica o vetorizador nos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formato (Linhas, Colunas) da matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Testando o modelo com algumas instâncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defina instâncias de teste dentro de uma lista\n",
    "testes = ['Esse governo está no início, vamos ver o que vai dar',\n",
    "          'Estou muito feliz com o governo de Minas esse ano',\n",
    "          'O estado de Minas Gerais decretou calamidade financeira!!!',\n",
    "          'A segurança desse país está deixando a desejar',\n",
    "          'O governador de Minas é mais uma vez do PT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplica a função de Pré-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in testes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a classificação com o modelo treinado.\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Função de Tags de Negações**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acrescenta uma tag _NEG encontrada após um 'não'.\n",
    "* Objetivo é dar mais peso para o modelo identificar uma inversão de sentimento da frase.\n",
    "* Exemplos: \n",
    "    - Eu gosto de cachorros, positivo.\n",
    "    - Eu **não** gosto de cachorros, negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['não','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplos de utilização da tag de negações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marque_negacao('Eu gosto do partido, votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marque_negacao('Eu Não gosto do partido, e também não votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando modelos com Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipelines são interessantes para reduzir código e automatizar fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline que atribui tag de negacoes nas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_simples.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_simples.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gera o modelo de negações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_negacoes.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_negacoes.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando os Modelos com Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_simples, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Medidas de validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelo com a Tag de Negações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_negacoes, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Avaliando modelo com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'eu gosto', 'gosto do' , 'do brasil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Considerações Finais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Considere aumentar a quantidade de dados de treino.\n",
    "\n",
    "* Pela sua simplicidade o Naive Bayes pode ser usado perfeitamente como um algoritmo de Baseline.\n",
    "\n",
    "* Considere alterar os parâmetros do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**www.minerandodados.com.br** - *A maior comunidade de Data Science do Brasil*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
